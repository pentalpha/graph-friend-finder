{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API >> https://facebook-sdk.readthedocs.io/en/latest/api.html\n",
    "### Get access token >> https://developers.facebook.com/tools/explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facebook-sdk in /home/pentalpha/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: requests in /home/pentalpha/anaconda3/lib/python3.6/site-packages (from facebook-sdk)\n"
     ]
    }
   ],
   "source": [
    "!pip install facebook-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict as ddict\n",
    "import facebook as fb\n",
    "import requests as req\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gets the categories of pages liked by the user\n",
    "#   token       user access token\n",
    "#   return      dictionary of categories found, each with it's own array of pages\n",
    "#       {c1 : [page1, page2, page3...], c2 : [page4, page5], c3 : [page6]...}\n",
    "def getCats(token):\n",
    "    cats = ddict(str)\n",
    "    graph = fb.GraphAPI(access_token=token, version='2.7')\n",
    "    resource = graph.get_object(\"me/likes?fields=name,category\")\n",
    "    #print(resource)\n",
    "    cats = dict()\n",
    "    while(True):\n",
    "        for page in resource['data']:\n",
    "            cat = page['category']\n",
    "            if not(cat in cats):\n",
    "                cats[cat] = []\n",
    "            cats[cat].append(page['id'])\n",
    "        # Attempt to make a request to the next page of data, if it exists.\n",
    "        try:\n",
    "            resource=req.get(resource['paging']['next']).json()\n",
    "        except KeyError:\n",
    "            print(\"Finished getting pages\")\n",
    "            # When there are no more pages (['paging']['next']), break from the\n",
    "            # loop and end the script.\n",
    "            break\n",
    "    return cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the pages that a given user liked\n",
    "#   user    id of a user\n",
    "#   token   access token\n",
    "#   return  array of page IDs\n",
    "#       [page1, page2, page3...]\n",
    "def getPagesList(user, token):\n",
    "    pages = list()\n",
    "    graph = fb.GraphAPI(access_token=token, version='2.7')\n",
    "    resource = graph.get_object(user+\"/likes?fields=name\")\n",
    "    #print(resource)\n",
    "    cats = dict()\n",
    "    while(True):\n",
    "        for page in resource['data']:\n",
    "            pages.append(page['id'])\n",
    "        # Attempt to make a request to the next page of data, if it exists.\n",
    "        try:\n",
    "            resource=req.get(resource['paging']['next']).json()\n",
    "        except KeyError:\n",
    "            print(\"Finished getting pages from user \" + user)\n",
    "            # When there are no more pages (['paging']['next']), break from the\n",
    "            # loop and end the script.\n",
    "            break\n",
    "    return pages\n",
    "\n",
    "\n",
    "def getPagesListFriends(user, token):\n",
    "    pages = list()\n",
    "    try:\n",
    "        graph = fb.GraphAPI(access_token=token, version='2.7')\n",
    "        resource = graph.get_object(user+\"?fields=likes{category,name}\")[\"likes\"]\n",
    "    except:\n",
    "        return pages\n",
    "    cats = dict()\n",
    "    while(True):\n",
    "        for page in resource['data']:\n",
    "            pages.append(page['id'])\n",
    "        # Attempt to make a request to the next page of data, if it exists.\n",
    "        try:\n",
    "            resource=req.get(resource['paging']['next']).json()\n",
    "        except KeyError:\n",
    "            print(\"Finished getting pages from user \" + user)\n",
    "            # When there are no more pages (['paging']['next']), break from the\n",
    "            # loop and end the script.\n",
    "            break\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Classifies pages by categories, the category with more pages gets 1.0\n",
    "#and the smaller categories get smaller and smaller classifications...\n",
    "#   cats        dictionary of categories found, each with it's own array of pages\n",
    "#       {c1 : [page1, page2, page3...], c2 : [page4, page5], c3 : [page6]...}\n",
    "#   return      dictionary of pages, each with it's own classification (0.0 < classification <= 1.0)\n",
    "#       {page1 : x, page2 : x, page4 : y, page6 : z}\n",
    "def classify(cats):\n",
    "    classification = ddict()\n",
    "    biggestCat = \"\"\n",
    "    biggestCatLen = 0\n",
    "    for cat, pages in cats.items():\n",
    "        if(len(pages) > biggestCatLen):\n",
    "            biggestCat = cat\n",
    "            biggestCatLen = len(pages)\n",
    "    for cat, pages in cats.items():\n",
    "        classify = len(pages)/biggestCatLen\n",
    "        for i in pages:\n",
    "            classification[i] = classify\n",
    "\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(cats):\n",
    "    listKey = list()\n",
    "    listValue = list()\n",
    "    listZero = list()\n",
    "    for key, value in cats.items():\n",
    "        listKey.append(key)\n",
    "        listValue.append(len(value))\n",
    "        listZero.append(0.0)\n",
    "    \n",
    "    d = {'name': listKey, 'frequency': listValue, 'normalize': listZero, 'weight': listZero}\n",
    "    normalization = pd.DataFrame(data=d)\n",
    "    normalization[\"normalize\"] = (normalization[\"frequency\"]/normalization[\"frequency\"].max())\n",
    "    normalization = normalization.sort_values([\"frequency\", \"name\"], ascending=[False, True])\n",
    "    \n",
    "    weights = [25, 18, 15, 12, 10, 8, 6, 4, 2, 1]\n",
    "    cont = 0\n",
    "    for row, value in normalization.iterrows():\n",
    "        if(cont < 10):\n",
    "            value[\"weight\"] = weights[cont] * value[\"normalize\"]\n",
    "        else:\n",
    "            value[\"weight\"] = weights[9] * value[\"normalize\"]\n",
    "        cont +=1\n",
    "    \n",
    "    return normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarityWith(user, classification, token):\n",
    "    otherUserPages = getPagesListFriends(user, token)\n",
    "    rate = 0.0\n",
    "    for page in otherUserPages:\n",
    "        if page in classification:\n",
    "            rate += classification[page]\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return dict { id1 : friend_name1, id2 : friend_name2 }\n",
    "def getFriends(user, token):\n",
    "    graph = fb.GraphAPI(access_token=token, version='2.7')\n",
    "    resource = graph.get_object(\"/\" + user + \"/friends\")\n",
    "    friends = dict()\n",
    "    while(True):\n",
    "        for friend in resource['data']:\n",
    "            friends[friend['id']] = friend['name']\n",
    "            # Attempt to make a request to the next page of data, if it exists.\n",
    "        try:\n",
    "            resource=req.get(resource['paging']['next']).json()\n",
    "        except KeyError:\n",
    "            print(\"Finished getting friends from user \" + user)\n",
    "            # When there are no more pages (['paging']['next']), break from the\n",
    "            # loop and end the script.\n",
    "            break\n",
    "\n",
    "    return friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUsersDict(user, token):\n",
    "    friends = getFriends(user, token)\n",
    "    ffriends = dict() \n",
    "    listFFriends = []\n",
    "    for idFriend in friends: \n",
    "        friendsOfFriends = getFriends(idFriend, token)\n",
    "        for idUser, name in friendsOfFriends.items():\n",
    "            if not idUser in ffriends and not idUser in friends:\n",
    "                ffriends[idUser] = name\n",
    "                listFFriends.append([idUser, name])\n",
    "    \n",
    "    count = 0\n",
    "    while len(listFFriends) < 400 and len(listFFriends) > count:\n",
    "        curruentID = listFFriends[count][0]\n",
    "        friendsCurrentID = getFriends(curruentID, token)\n",
    "        for idUser, name in friendsOfFriends.items():\n",
    "            if not idUser in ffriends:\n",
    "                ffriends[idUser] = name\n",
    "                listFFriends.append([idUser, name])\n",
    "        count+=1\n",
    "    return ffriends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#START\n",
    "#this is my token (PitÃ¡goras)\n",
    "token = \"EAACEdEose0cBABQrzTCSD1uQFNevppuRxaGVTPL49CHb1MhMWgMty8kaDZCFNOKZBCtvNa7hzpzCIyvnA4JtLZBF9SqWsyMJ1d8CyQXqBaqZB8hwUOyJvhCoZBLBjSm1yLJBWHZBrd6ywTZAnjF4ZBHn7knuOk5mafTe2K4QoHskakjm7t2yMbfYSXYAi8E0a8kiLG4OYZB0cVSYDKixXERD2Pj9wXBPmFXkvaseQqtUyPQZDZD\"\n",
    " \n",
    "#ID of \"Pitagoras\"\n",
    "otherPersonID = \"10208935375967359\"\n",
    "raiID = \"739425496128479\"\n",
    "anaID = \"765831436837419\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished getting friends from user me\n",
      "Finished getting pages\n",
      "Finished getting pages from user 10208935375967359\n"
     ]
    }
   ],
   "source": [
    "#users = getUsersDict('me', token)\n",
    "myfriends = getFriends('me', token)\n",
    "cats = getCats(token)\n",
    "classf = classify(cats)\n",
    "\n",
    "otherUserPages = getPagesList(otherPersonID, token)\n",
    "#similarity = similarityWith(otherPersonID, classf, token)\n",
    "#print(\"Similarity with \" + otherPersonID + \": \" + str(similarity))\n",
    "#example print classifications\n",
    "#count = 0\n",
    "#for page, classification in classf.items():\n",
    "#    print(page + \": \" + str(classification))\n",
    "#    count = count + 1\n",
    "#    if(count > 20):\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcSimilarityAndAddTo(key, classf, token, similarityDict):\n",
    "    ratio = similarityWith(key, classf, token)\n",
    "    if(ratio > 0):\n",
    "        similarityDict[key] = ratio\n",
    "        print(key + \" similarity with me is \" + str(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished getting pages from user 10208935375967359\n",
      "10208935375967359 similarity with me is 1.1578947368421053\n",
      "Finished getting pages from user 862034200484130\n",
      "862034200484130 similarity with me is 2.810526315789474\n",
      "Finished getting pages from user 998100796886441\n",
      "998100796886441 similarity with me is 10.505263157894733\n",
      "Finished getting pages from user 967446623299200\n",
      "967446623299200 similarity with me is 1.7578947368421054\n",
      "Finished getting pages from user 773541116034720\n",
      "773541116034720 similarity with me is 4.821052631578947\n"
     ]
    }
   ],
   "source": [
    "#listKey = list()\n",
    "#listValue = list()\n",
    "#listSimilarity = list()\n",
    "#selectedFriends = dict()\n",
    "count = 0\n",
    "limit = 5\n",
    "similarityDict = dict()\n",
    "for key, value in myfriends.items():\n",
    "    if(count > limit):\n",
    "        break\n",
    "    calcSimilarityAndAddTo(key, classf, token, similarityDict)\n",
    "    count = count + 1\n",
    "    ##if(similarity > 0):\n",
    "    ##    similarityDict[key] = similarity\n",
    "    ##    listKey.append(key)\n",
    "    ##    listValue.append(value)\n",
    "    ##    selectedFriends[key] = value\n",
    "    ##    listSimilarity.append(similarity)\n",
    "    ##    listSimilarity.append([key, value, similarity])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10208935375967359': 1.1578947368421053, '862034200484130': 2.810526315789474, '998100796886441': 10.505263157894733, '967446623299200': 1.7578947368421054, '773541116034720': 4.821052631578947}\n",
      "user-id\n",
      "10208935375967359     1.157895\n",
      "773541116034720       4.821053\n",
      "862034200484130       2.810526\n",
      "967446623299200       1.757895\n",
      "998100796886441      10.505263\n",
      "Name: similarity, dtype: float64\n",
      "                   similarity\n",
      "user-id                      \n",
      "998100796886441     10.505263\n",
      "773541116034720      4.821053\n",
      "862034200484130      2.810526\n",
      "967446623299200      1.757895\n",
      "10208935375967359    1.157895\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#d = {'id': listKey, 'name': listValue, 'similarity': listSimilarity}\n",
    "#df_similarity = pd.DataFrame(data=d)\n",
    "#print(similarityDict)\n",
    "s = pd.Series(similarityDict, name='similarity')\n",
    "s.index.name = 'user-id'\n",
    "s.reset_index()\n",
    "#print(s)\n",
    "df_similarity = s.to_frame()\n",
    "print (df_similarity.sort_values([\"similarity\"], ascending=[False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
